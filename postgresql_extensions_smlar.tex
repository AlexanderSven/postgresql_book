\section{Smlar}
\textbf{Лицензия}: Open Source

\textbf{Ссылка}: \href{http://sigaev.ru/git/gitweb.cgi?p=smlar.git;a=blob;hb=HEAD;f=README}{sigaev.ru}

Поиск похожестей в больших базах данных является важным вопросом в настоящее время для таких систем как блоги (похожие статьи), интернет-магазины (похожие продукты), хостинг изображений (похожие изображения, поиск дубликатов изображений) и т.д. PostgreSQL позволяет сделать такой поиск более легким. Прежде всего, необходимо понять, как мы будем вычислять сходство двух объектов.

\subsection{Похожесть}

Любой объект может быть описан как список характеристик. Например, статья в блоге может быть описана тегами, продукт в интернет-магазине может быть описан размером, весом, цветом и т.д. Это означает, что для каждого объекта можно создать цифровую подпись~--- массив чисел, описывающих объект (отпечатки пальцев\footnote{http://en.wikipedia.org/wiki/Fingerprint}, n-grams\footnote{http://en.wikipedia.org/wiki/N-gram}). Тоесть нужно создать массив из цифр для описания каждого объекта. Что делать дальше?

\subsection{Расчет похожести}

Есть несколько методов вычисления похожести сигнатур обьектов. Прежде всего, легенда для расчетов:

$N_a$, $N_b$~-- количество уникальных элементов в массивах

$N_u$~-- количество уникальных элементов при объединении массивов

$N_i$~-- количество уникальных элементов при пересечение массивов

Один из простейших расчетов похожести двух объектов - количество уникальных элементов при пересечение массивов делить на количество уникальных элементов в двух массивах:

\begin{equation}
 \label{eq:smlar1}
 S(A,B) = \frac{N_{i}}{(N_{a}+N_{b})}
\end{equation}

или проще

\begin{equation}
 \label{eq:smlar2}
 S(A,B) = \frac{N_{i}}{N_{u}}
\end{equation}

Преимущества:

\begin{itemize}
\item Легко понять
\item Скорость расчета: $N * \log{N}$
\item Хорошо работает на похожих и больших $N_a$ и $N_b$
\end{itemize}

Также похожесть можно рассчитана по формуле косинусов\footnote{http://en.wikipedia.org/wiki/Law\_of\_cosines}:

\begin{equation}
 \label{eq:smlar3}
 S(A,B) = \frac{N_{i}}{\sqrt{N_{a}*N_{b}}}
\end{equation}

Преимущества:

\begin{itemize}
\item Скорость расчета: $N * \log{N}$
\item Отлично работает на больших $N$
\end{itemize}

Но у обоих этих методов есть общие проблемы:

\begin{itemize}
\item Если элементов мало то разброс похожестей не велик
\item Глобальная статистика: частые элементы ведут к тому, что вес ниже
\item Спамеры и недобросовестные пользователи. Один <<залетевший дятел>> разрушит цивилизацию - алгоритм перестанет работать на Вас.
\end{itemize}

Для избежания этих проблем можно воспользоватся TF/IDF\footnote{http://en.wikipedia.org/wiki/Tf*idf} метрикой:

\begin{equation}
 \label{eq:smlar4}
 S(A,B) = \frac{\sum_{i < N_{a}, j < N_{b}, A_{i} = B_{j}}TF_{i} * TF_{j}}{\sqrt{\sum_{i < N_{a}}TF_{i}^{2} * \sum_{j < N_{b}}TF_{j}^{2}}}
\end{equation}

где инвертированный вес элемента в коллекции:

\begin{equation}
 \label{eq:smlar5}
 IDF_{element} = \log{(\frac{N_{objects}}{N_{objects\ with\ element}} + 1)}
\end{equation}

и вес элемента в массиве:

\begin{equation}
 \label{eq:smlar6}
 TF_{element} = IDF_{element} * N_{occurrences}
\end{equation}

Не пугайтесь! Все эти алгоритмы встроены в smlar расширение, учить (или даже глубоко понимать) их не нужно. Главное понимать, что для TF/IDF метрики требуются вспомогательная таблица для хранения данных, по сравнению с другими простыми метриками.

