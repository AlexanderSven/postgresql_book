\section{Postgresql-hll}

\href{https://github.com/aggregateknowledge/postgresql-hll}{Postgresql-hll} расширение добавляет новый тип поля \lstinline!hll!, который представляет собой \href{https://en.wikipedia.org/wiki/HyperLogLog}{HyperLogLog} структуру данных. Что такое HyperLogLog алгоритм и зачем он может потребоватся?

На сегодняшний день широко распространена задача подсчета количества уникальных элементов (count-distinct problem) в данных, которые могут содержать повторяющиеся элементы. Например, сколько уникальных IP-адресов подключалось к серверу за последний час? Сколько различных слов в большом куске текстов? Какое количество уникальных посетителей побывало на популярном сайте за день? Сколько уникальных URL было запрошено через прокси-сервер? Данную задачу можно решить <<в лоб>>: пройтись по всем элементам и убрать дубликаты, после этого посчитать их количество (например использовать множество, set). Трудности в таком подходе возникают при увеличении масштаба. С минимальными затратами можно подсчитать тысячу или даже миллион уникальных посетителей, IP-адресов, URL или слов. А что если речь идет о 100 миллионах уникальных элементов на один сервер при наличии тысяч серверов? Теперь это уже становится интересным.

Теперь текущее решение будет выглядеть так: необходимо сформировать множества (set) уникальных элементов для каждого из 1000 серверов, каждое из которых может содержать около 100 миллионов уникальных элементов, а затем подсчитать количество уникальных элементов в объединении этих множеств. Другими словами, мы имеем дело с распределенным вариантом задачи подсчета уникальных элементов. Хоть это решение является вполне логичным, на практике этот подход обойдется высокой ценой. Для примера возьмем URL, средняя длина которого составляет 76 символов. В нашем случае один сервер обслуживает около 100 миллионов уникальных URL, следовательно, размер файла с их перечнем составит около 7,6 ГБ. Даже если каждый URL преобразовать в 64-битный хеш, размер файла составит 800 МБ. Это намного лучше, но не забывайте, что речь идет о 1000 серверов. Каждый сервер отправляет файл с перечнем уникальных URL на центральный сервер, следовательно, при наличии 1000 серверов функция объединения множеств должна обработать 800 ГБ данных. Если такая операция должна выполняться часто, тогда необходимо будет либо установить систему для обработки больших данных (и нанять команду для ее обслуживания), либо найти другое решение.

И вот на сцену выходит HyperLogLog алгоритм. Этот алгоритм реализует вероятностный подход к задаче подсчета уникальных элементов и базируется на двух следующих положениях:

\begin{itemize}
  \item вероятность того, что любой данный бит двоичного представления случайного числа равен единице, составляет 50\%;
  \item вероятность того, что совместно произойдут два независимых случайных события $A$ и $B$, вычисляется по формуле $P(A)*P(B)$. Таким образом, если вероятность равенства единице одного любого бита случайного числа составляет 50\%, тогда вероятность равенства единице двух любых битов составляет 25\%, трех~--- 12,5\% и т.д;
\end{itemize}

Вспомним еще одно базовое положение теории вероятностей, согласно которому ожидаемое количество испытаний, необходимое для наступления события, вычисляется по формуле $1/P(event)$. Следовательно, если $P(one\ specific\ bit\ set) = 50\%$, то ожидаемое количество испытаний равно 2. Для двух битов~--- 4, для трех битов~--- 8 и т.д.

В общем случае входные значения не являются равномерно распределенными случайными числами, поэтому необходим способ преобразования входных значений к равномерному распределению, т.е. необходима хеш-функция. Обратите внимание, в некоторых случаях распределение, получаемое на выходе хеш-функции, не оказывает существенное влияние на точность системы. Однако HyperLogLog очень чувствителен в этом отношении. Если выход хеш-функции не соответствует равномерному распределению, алгоритм теряет точность, поскольку не выполняются базовые допущения, лежащие в его основе.

Рассмотрим алгоритм подробно. Вначале необходимо хешировать все элементы исследуемого набора. Затем нужно подсчитать количество последовательных начальных битов, равных единице, в двоичном представлении каждого хеша и определить максимальное значение этого количества среди всех хешей. Если максимальное количество единиц обозначить $n$, тогда количество уникальных элементов в наборе можно оценить, как $2^n$. То есть, если максимум один начальный бит равен единице, тогда количество уникальных элементов, в среднем, равно 2; если максимум три начальных бита равны единице, в среднем, мы можем ожидать 8 уникальных элементов и т.д.

Подход, направленный на повышение точности оценки и являющийся одной из ключевых идей HyperLogLog, заключается в следующем: разделяем хеши на подгруппы на основании их конечных битов, определяем максимальное количество начальных единиц в каждой подгруппе, а затем находим среднее. Этот подход позволяет получить намного более точную оценку общего количества уникальных элементов. Если мы имеем $m$ подгрупп и $n$ уникальных элементов, тогда, в среднем, в каждой подгруппе будет $n/m$ уникальных элементов. Таким образом, нахождение среднего по всем подгруппам дает достаточно точную оценку величины $log_2{(n/m)}$, а отсюда легко можно получить необходимое нам значение. Более того, HyperLogLog позволяет обрабатывать по отдельности различные варианты группировок, а затем на основе этих данных находить итоговую оценку. Следует отметить, что для нахождения среднего HyperLogLog использует среднее гармоническое, которое обеспечивает лучшие результаты по сравнению со средним арифметическим (более подробную информацию можно найти в оригинальных публикациях, посвященных \href{http://www.ic.unicamp.br/~celio/peer2peer/math/bitmap-algorithms/durand03loglog.pdf}{LogLog} и \href{http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf}{HyperLogLog}).

Вернемся к задачи. По условию существует 1000 серверов и 100 миллионов уникальных URL на каждый сервер, следовательно, центральный сервер должен обрабатывать 800 ГБ данных при каждом выполнении простого варианта алгоритма. Это также означает, что 800 ГБ данных каждый раз необходимо передавать по сети. HyperLogLog меняет ситуацию кардинально. Согласно анализу, проведенному авторами оригинальной публикации, HyperLogLog обеспечивает точность около 98\% при использовании всего 1.5 КБ памяти. Каждый сервер формирует соответствующий файл размером 1.5 КБ, а затем отправляет его на центральный сервер. При наличии 1000 серверов, центральный сервер обрабатывает всего 1.5 МБ данных при каждом выполнении алгоритма. Другими словами, обрабатывается лишь 0.0002\% данных по сравнению с предыдущим решением. Это полностью меняет экономический аспект задачи. Благодаря HyperLogLog, возможно выполнять такие операции чаще и в большем количестве. И все это ценой всего лишь 2\% погрешности.



\subsection{Заключение}

Более подробно о использовании расширения можно ознакомиться через \href{https://github.com/aggregateknowledge/postgresql-hll/blob/master/README.markdown}{официальную документацию}.
